{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPLYCHpuN4hzW6roXbrqQ0q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProEarth/Statistics/blob/main/Portfolio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-iV7qmQvwo2i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc399727-5401-445b-dd27-983d2e6da886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/ExpHS300"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anRJwJdDwrsM",
        "outputId": "487903ed-4cf3-48b5-de7f-702a548e4131"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ExpHS300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "1luWpISbaUyv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = \"ExpHS300\"\n",
        "years = ['2018']  # 需要批量就把年份列表扩展\n",
        "print('years:', years)\n",
        "for y in years:\n",
        "  in_dir  = os.path.join(y)\n",
        "  print(in_dir)\n",
        "# 当前默认路径\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ydQJnataPiQ",
        "outputId": "8d487e1e-cb59-4b07-fb82-eed26429a2e2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "years: ['2018']\n",
            "2018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(in_dir, exist_ok=True)\n",
        "\n",
        "cov_path = os.path.join(in_dir, 'YEAR_COV_MATRIX.xlsx')\n",
        "mv_path  = os.path.join(in_dir, 'YEAR_MEAN_VAR.xlsx')\n",
        "print(cov_path)\n",
        "print(mv_path)\n",
        "if not os.path.exists(cov_path) or not os.path.exists(mv_path):\n",
        "    raise FileNotFoundError(\"找不到输入文件，请确认路径中包含 YEAR_COV_MATRIX.xlsx 与 YEAR_MEAN_VAR.xlsx\")\n",
        "\n",
        "# 读取\n",
        "cov = pd.read_excel(cov_path, index_col=0)\n",
        "mv = pd.read_excel(mv_path,  index_col=0)\n",
        "print(cov)\n",
        "print(mv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOkY9VSlaAZk",
        "outputId": "4e7a365e-71e4-49cf-e194-24dd8041c3d6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2018/YEAR_COV_MATRIX.xlsx\n",
            "2018/YEAR_MEAN_VAR.xlsx\n",
            "               1         2         4         5         6         7         8  \\\n",
            "1       4.535431  3.730117  0.088126  1.683785  2.236630  0.960117  0.984999   \n",
            "2       3.730117  7.181717  0.146358  2.101776  2.942103  1.672684  0.725868   \n",
            "4       0.088126  0.146358  3.435273  0.807178  0.920988  0.945150  0.354565   \n",
            "5       1.683785  2.101776  0.807178  5.205338  3.188975  2.611790  0.935925   \n",
            "6       2.236630  2.942103  0.920988  3.188975  6.080228  2.858541  0.786647   \n",
            "...          ...       ...       ...       ...       ...       ...       ...   \n",
            "603993  2.816789  3.310698  0.840948  3.146913  3.570762  2.032004  0.969182   \n",
            "603996  1.295078  1.677418  0.699434  2.358211  2.590597  2.061971  1.122172   \n",
            "603997  0.417136  0.896821  0.467820  1.204451  0.587639  0.816426  1.156901   \n",
            "603998  1.618399  2.308008  0.768518  2.708261  2.722322  2.018428  1.048530   \n",
            "603999  2.046755  2.631105  1.546406  3.348920  3.074646  2.636994  1.347427   \n",
            "\n",
            "               9        10        11  ...    603987    603988    603989  \\\n",
            "1       1.564445  1.241908  2.425295  ...  1.406625  1.246170  1.265107   \n",
            "2       2.152880  2.186113  3.513228  ...  1.740675  1.783533  1.646656   \n",
            "4       1.293778  1.243949  0.982717  ...  1.075082  1.159592  0.875467   \n",
            "5       3.417945  2.635222  3.634339  ...  2.829966  3.910650  2.102641   \n",
            "6       3.038592  2.331557  4.805026  ...  2.528641  3.247296  1.791425   \n",
            "...          ...       ...       ...  ...       ...       ...       ...   \n",
            "603993  3.937766  3.230698  4.201686  ...  2.924095  3.706717  2.761925   \n",
            "603996  3.101395  1.971032  3.158952  ...  2.616546  4.049329  2.676261   \n",
            "603997  1.656970  0.791326  1.534126  ...  0.982570  1.505084  1.031863   \n",
            "603998  3.207243  1.955074  2.770311  ...  3.404682  3.339348  2.410504   \n",
            "603999  4.228325  3.076559  3.378592  ...  3.269305  3.871659  2.660663   \n",
            "\n",
            "          603990    603991    603993    603996    603997    603998    603999  \n",
            "1       0.905815  1.390466  2.816789  1.295078  0.417136  1.618399  2.046755  \n",
            "2       1.168295  1.619782  3.310698  1.677418  0.896821  2.308008  2.631105  \n",
            "4       0.516365  1.179246  0.840948  0.699434  0.467820  0.768518  1.546406  \n",
            "5       2.074504  3.392447  3.146913  2.358211  1.204451  2.708261  3.348920  \n",
            "6       1.963065  3.544389  3.570762  2.590597  0.587639  2.722322  3.074646  \n",
            "...          ...       ...       ...       ...       ...       ...       ...  \n",
            "603993  2.480570  3.969059  9.759581  2.605339  1.044154  2.831941  4.064645  \n",
            "603996  1.834451  3.256878  2.605339  9.684372  1.066072  3.714424  3.266773  \n",
            "603997  0.574942  1.036888  1.044154  1.066072  3.729424  0.663560  2.007321  \n",
            "603998  1.521961  3.231436  2.831941  3.714424  0.663560  6.856915  3.151592  \n",
            "603999  2.379609  4.208605  4.064645  3.266773  2.007321  3.151592  9.051670  \n",
            "\n",
            "[3570 rows x 3570 columns]\n",
            "            mean  variance\n",
            "Symbol                    \n",
            "1      -0.114728  4.535431\n",
            "2      -0.057515  7.181717\n",
            "4      -0.120238  3.435273\n",
            "5      -0.152953  5.205338\n",
            "6      -0.221218  6.080228\n",
            "...          ...       ...\n",
            "603993 -0.194603  9.759581\n",
            "603996 -0.316834  9.684372\n",
            "603997 -0.130378  3.729424\n",
            "603998 -0.324061  6.856915\n",
            "603999 -0.142454  9.051670\n",
            "\n",
            "[3570 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cov)\n",
        "print(np.diag(cov.values))\n",
        "std = np.sqrt(np.diag(cov.values))\n",
        "corr = cov.div(std, axis=0).div(std, axis=1)\n",
        "np.fill_diagonal(corr.values, 1.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWgpbp5ohLvN",
        "outputId": "3231fab5-56da-485d-87cf-e9c3a611ba98"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               1         2         4         5         6         7         8  \\\n",
            "1       4.535431  3.730117  0.088126  1.683785  2.236630  0.960117  0.984999   \n",
            "2       3.730117  7.181717  0.146358  2.101776  2.942103  1.672684  0.725868   \n",
            "4       0.088126  0.146358  3.435273  0.807178  0.920988  0.945150  0.354565   \n",
            "5       1.683785  2.101776  0.807178  5.205338  3.188975  2.611790  0.935925   \n",
            "6       2.236630  2.942103  0.920988  3.188975  6.080228  2.858541  0.786647   \n",
            "...          ...       ...       ...       ...       ...       ...       ...   \n",
            "603993  2.816789  3.310698  0.840948  3.146913  3.570762  2.032004  0.969182   \n",
            "603996  1.295078  1.677418  0.699434  2.358211  2.590597  2.061971  1.122172   \n",
            "603997  0.417136  0.896821  0.467820  1.204451  0.587639  0.816426  1.156901   \n",
            "603998  1.618399  2.308008  0.768518  2.708261  2.722322  2.018428  1.048530   \n",
            "603999  2.046755  2.631105  1.546406  3.348920  3.074646  2.636994  1.347427   \n",
            "\n",
            "               9        10        11  ...    603987    603988    603989  \\\n",
            "1       1.564445  1.241908  2.425295  ...  1.406625  1.246170  1.265107   \n",
            "2       2.152880  2.186113  3.513228  ...  1.740675  1.783533  1.646656   \n",
            "4       1.293778  1.243949  0.982717  ...  1.075082  1.159592  0.875467   \n",
            "5       3.417945  2.635222  3.634339  ...  2.829966  3.910650  2.102641   \n",
            "6       3.038592  2.331557  4.805026  ...  2.528641  3.247296  1.791425   \n",
            "...          ...       ...       ...  ...       ...       ...       ...   \n",
            "603993  3.937766  3.230698  4.201686  ...  2.924095  3.706717  2.761925   \n",
            "603996  3.101395  1.971032  3.158952  ...  2.616546  4.049329  2.676261   \n",
            "603997  1.656970  0.791326  1.534126  ...  0.982570  1.505084  1.031863   \n",
            "603998  3.207243  1.955074  2.770311  ...  3.404682  3.339348  2.410504   \n",
            "603999  4.228325  3.076559  3.378592  ...  3.269305  3.871659  2.660663   \n",
            "\n",
            "          603990    603991    603993    603996    603997    603998    603999  \n",
            "1       0.905815  1.390466  2.816789  1.295078  0.417136  1.618399  2.046755  \n",
            "2       1.168295  1.619782  3.310698  1.677418  0.896821  2.308008  2.631105  \n",
            "4       0.516365  1.179246  0.840948  0.699434  0.467820  0.768518  1.546406  \n",
            "5       2.074504  3.392447  3.146913  2.358211  1.204451  2.708261  3.348920  \n",
            "6       1.963065  3.544389  3.570762  2.590597  0.587639  2.722322  3.074646  \n",
            "...          ...       ...       ...       ...       ...       ...       ...  \n",
            "603993  2.480570  3.969059  9.759581  2.605339  1.044154  2.831941  4.064645  \n",
            "603996  1.834451  3.256878  2.605339  9.684372  1.066072  3.714424  3.266773  \n",
            "603997  0.574942  1.036888  1.044154  1.066072  3.729424  0.663560  2.007321  \n",
            "603998  1.521961  3.231436  2.831941  3.714424  0.663560  6.856915  3.151592  \n",
            "603999  2.379609  4.208605  4.064645  3.266773  2.007321  3.151592  9.051670  \n",
            "\n",
            "[3570 rows x 3570 columns]\n",
            "[4.53543137 7.18171694 3.43527348 ... 3.72942358 6.85691461 9.05167036]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(corr)\n",
        "print(mv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZplNmEzPbptA",
        "outputId": "9e4c5614-d27c-46b4-eb99-657c57747e3c",
        "collapsed": true
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               1         2         4         5         6         7         8  \\\n",
            "1       1.000000  0.653580  0.022326  0.346540  0.425917  0.123170  0.202717   \n",
            "2       0.653580  1.000000  0.029466  0.343754  0.445229  0.170526  0.118716   \n",
            "4       0.022326  0.029466  1.000000  0.190882  0.201518  0.139319  0.083845   \n",
            "5       0.346540  0.343754  0.190882  1.000000  0.566848  0.312756  0.179796   \n",
            "6       0.425917  0.445229  0.201518  0.566848  1.000000  0.316721  0.139825   \n",
            "...          ...       ...       ...       ...       ...       ...       ...   \n",
            "603993  0.423379  0.395448  0.145236  0.441514  0.463538  0.177705  0.135973   \n",
            "603996  0.195412  0.201137  0.121264  0.332141  0.337601  0.181025  0.158048   \n",
            "603997  0.101426  0.173289  0.130701  0.273366  0.123404  0.115502  0.262567   \n",
            "603998  0.290210  0.328896  0.158347  0.453317  0.421614  0.210591  0.175501   \n",
            "603999  0.319442  0.326332  0.277318  0.487883  0.414449  0.239462  0.196293   \n",
            "\n",
            "               9        10        11  ...    603987    603988    603989  \\\n",
            "1       0.296375  0.192885  0.400044  ...  0.276476  0.148507  0.231066   \n",
            "2       0.324113  0.269822  0.460516  ...  0.271889  0.168907  0.239005   \n",
            "4       0.281624  0.221994  0.186252  ...  0.242800  0.158783  0.183729   \n",
            "5       0.604409  0.382042  0.559569  ...  0.519213  0.435015  0.358474   \n",
            "6       0.497168  0.312756  0.684524  ...  0.429256  0.334227  0.282590   \n",
            "...          ...       ...       ...  ...       ...       ...       ...   \n",
            "603993  0.508540  0.342058  0.472455  ...  0.391800  0.301130  0.343885   \n",
            "603996  0.402079  0.209497  0.356582  ...  0.351950  0.330238  0.334511   \n",
            "603997  0.346166  0.135536  0.279057  ...  0.212976  0.197797  0.207835   \n",
            "603998  0.494149  0.246955  0.371635  ...  0.544253  0.323651  0.358064   \n",
            "603999  0.567015  0.338236  0.394479  ...  0.454862  0.326597  0.343988   \n",
            "\n",
            "          603990    603991    603993    603996    603997    603998    603999  \n",
            "1       0.238577  0.244877  0.423379  0.195412  0.101426  0.290210  0.319442  \n",
            "2       0.244532  0.226694  0.395448  0.201137  0.173289  0.328896  0.326332  \n",
            "4       0.156269  0.238628  0.145236  0.121264  0.130701  0.158347  0.277318  \n",
            "5       0.510020  0.557681  0.441514  0.332141  0.273366  0.453317  0.487883  \n",
            "6       0.446552  0.539112  0.463538  0.337601  0.123404  0.421614  0.414449  \n",
            "...          ...       ...       ...       ...       ...       ...       ...  \n",
            "603993  0.445383  0.476507  1.000000  0.267987  0.173073  0.346182  0.432457  \n",
            "603996  0.330650  0.392521  0.267987  1.000000  0.177390  0.455818  0.348914  \n",
            "603997  0.166994  0.201376  0.173073  0.177390  1.000000  0.131218  0.345487  \n",
            "603998  0.326014  0.462838  0.346182  0.455818  0.131218  1.000000  0.400038  \n",
            "603999  0.443648  0.524652  0.432457  0.348914  0.345487  0.400038  1.000000  \n",
            "\n",
            "[3570 rows x 3570 columns]\n",
            "            mean  variance\n",
            "Symbol                    \n",
            "1      -0.114728  4.535431\n",
            "2      -0.057515  7.181717\n",
            "4      -0.120238  3.435273\n",
            "5      -0.152953  5.205338\n",
            "6      -0.221218  6.080228\n",
            "...          ...       ...\n",
            "603993 -0.194603  9.759581\n",
            "603996 -0.316834  9.684372\n",
            "603997 -0.130378  3.729424\n",
            "603998 -0.324061  6.856915\n",
            "603999 -0.142454  9.051670\n",
            "\n",
            "[3570 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GetNetwork:\n",
        "    def __init__(self,mv,corr):\n",
        "        self.mv = mv\n",
        "        self.df = corr\n",
        "\n",
        "    def df2net(self, net_df):\n",
        "      col_list = list(net_df.columns)\n",
        "      net_df = net_df.copy()\n",
        "      net_df.index = col_list\n",
        "\n",
        "      g = nx.Graph()\n",
        "      for i in range(len(col_list)):\n",
        "        for j in range(i + 1, len(col_list)):   # 只看上三角\n",
        "          w = net_df.iat[i, j]\n",
        "          if pd.notna(w) and w != 0:\n",
        "            g.add_edge(col_list[i], col_list[j], weight=float(w))\n",
        "      return g\n",
        "\n",
        "\n",
        "    def net2df(self, ntx):\n",
        "      nodelist = list(ntx.nodes)\n",
        "      # 等价但更安全：直接得到 pandas DataFrame，列行顺序一致\n",
        "      df = nx.to_pandas_adjacency(ntx, nodelist=nodelist, dtype=float, weight='weight')\n",
        "      return df\n",
        "\n",
        "    def fully_connected_weight(self):\n",
        "        return (1 - self.df) / 2\n",
        "\n",
        "    def minimum_spanning_tree(self, input_graph):\n",
        "        # 最小生成树Kruskal算法\n",
        "        # 现在假设一个图有m个节点，n条边。\n",
        "        # 首先，需要把m个节点看成m个独立的生成树，并且把n条边按照从小到大的数据进行排列。\n",
        "        # 在n条边中，依次取出其中的每一条边，如果发现边的两个节点分别位于两棵树上，那么把两棵树合并成为一颗树；\n",
        "        # 如果树的两个节点位于同一棵树上，那么忽略这条边，继续运行。\n",
        "        # 等到所有的边都遍历结束之后，如果所有的生成树可以合并成一条生成树，那么它就是我们寻找的最小生成树，反之则没有最小生成树。\n",
        "        print('计算最小生成树……')\n",
        "        mst_network = nx.minimum_spanning_tree(input_graph, algorithm='kruskal')\n",
        "        return mst_network\n",
        "\n",
        "    def length(self, g2):\n",
        "        length_df = pd.DataFrame(nx.floyd_warshall_numpy(g2, weight='weight'),\n",
        "                                 index=g2.nodes, columns=g2.nodes)\n",
        "        length_df = length_df[length_df.index]\n",
        "        length_df = length_df.reindex(index=length_df.index)\n",
        "\n",
        "        return length_df\n",
        "\n",
        "    def neighbor(self, network_df):\n",
        "        cols = network_df.columns.values\n",
        "        mask = network_df.gt(0.0).values\n",
        "        out = [cols[x].tolist() for x in mask]\n",
        "        return out\n",
        "\n",
        "    def get_feature(self, network_df):\n",
        "\n",
        "        # bet_cen = nx.betweenness_centrality(g)\n",
        "        #                     deg = nx.degree(g)\n",
        "        #                     deg_w = nx.degree(g, weight='weight')\n",
        "\n",
        "        deg_w  = list(nx.degree(self.df2net(network_df), weight='weight'))\n",
        "        deg_df = pd.DataFrame(deg_w, columns=['stk', 'Deg']).set_index('stk')\n",
        "\n",
        "        # print(deg_df)\n",
        "\n",
        "        # Calculate mean of each column and create DataFrame with correct index and columns\n",
        "        mean_series = network_df.mean()\n",
        "        mean_df = pd.DataFrame(mean_series, columns=['Closeness'])\n",
        "        mean_df.index.name = 'stk' # Set index name for consistency\n",
        "\n",
        "        # mean_df['div(Closeness)'] = 1 / (1 + mean_df['Closeness'])\n",
        "        # for index, row in mean_df.iterrows():\n",
        "            # mean_df.loc[index, 'Sqrt(ADegree)'] = np.sqrt(deg_df.loc[index, 'Deg'])\n",
        "            # mean_df.loc[index, 'ADegree'] = deg_df.loc[index, 'Deg']\n",
        "            # mean_df.loc[index, 'div(ADegree)'] = 1 / (np.sqrt(deg_df.loc[index, 'Deg']) + 1)\n",
        "            # mean_df.loc[index, 'div(ADegree)'] = 1 / (deg_df.loc[index, 'Deg'] + 1)\n",
        "            # mean_df.loc[index, 'Sqrt(div(ADegree))'] = 1 / (np.sqrt(deg_df.loc[index, 'Deg']) + 1)\n",
        "            # mean_df.loc[index, '1Log(Degree+1)'] = 1 / (np.log(deg_df.loc[index, 'Deg'] + 1))\n",
        "            # mean_df.loc[index, '1(1+Exp(-Degree))'] = 1 / (np.log(deg_df.loc[index, 'Deg']) + 1)\n",
        "\n",
        "        g = self.df2net(network_df)\n",
        "        for node in g.nodes:\n",
        "            adiv = 0\n",
        "\n",
        "            for n_node in g.neighbors(node):\n",
        "                adiv += 1 / (1 + g.edges[node, n_node]['weight'])\n",
        "                # print( node,n_node,g.edges[node, n_node]['weight'])\n",
        "            mean_df.loc[node, 'WDegree'] = adiv\n",
        "            # mean_df.loc[node, 'Sqrt(WDegree)'] = np.sqrt(adiv)\n",
        "            # mean_df.loc[node, 'Sqrt(div(WDegree))'] = 1 / (1 + np.sqrt(adiv))\n",
        "            # mean_df.loc[node, 'div(WDegree)'] = 1 / (1 + adiv)\n",
        "\n",
        "        mm_df = self.mv.copy()\n",
        "        print('get feature')\n",
        "        mean_df['E[return]'] = mm_df['mean']\n",
        "        # mean_df['divE[return]'] = 1/(1+mm_df['mean'])\n",
        "        print(mean_df)\n",
        "        print(mean_df.columns)\n",
        "        # -----------------------------------\n",
        "                # --- 用网络的列名，避免 self.stk_list 带来的问题 ---\n",
        "        cols = list(network_df.columns)\n",
        "\n",
        "        # --- 向量化计算 pairwise mean squared difference ---\n",
        "        # M: (n_rows x n_nodes) 的邻接矩阵（这里是 MST 的加权邻接）\n",
        "        M = network_df.values.astype(float)\n",
        "\n",
        "        # E[x^2]，按行求平均（列向量）\n",
        "        S = (M ** 2).mean(axis=0)                    # shape: (n_nodes,)\n",
        "\n",
        "        # E[xy]，按行求平均：E[xy] = (M^T M) / n_rows\n",
        "        n_rows = M.shape[0]\n",
        "        C = (M.T @ M) / n_rows                       # shape: (n_nodes, n_nodes)\n",
        "\n",
        "        # E[(x - y)^2] = E[x^2] + E[y^2] - 2E[xy]\n",
        "        msd = S[:, None] + S[None, :] - 2.0 * C      # (n_nodes, n_nodes)\n",
        "\n",
        "        # 你的做法：str_df = 1 / (1 + str_df)\n",
        "        str_mat = 1.0 / (1.0 + msd)\n",
        "\n",
        "        str_df = pd.DataFrame(str_mat, index=cols, columns=cols)\n",
        "\n",
        "        # （可选）如果你希望对角线是 E[x^2] 的同样转换：\n",
        "        # np.fill_diagonal(str_df.values, 1.0 / (1.0 + S))\n",
        "        # 否则保持当前推导也可行\n",
        "\n",
        "        return mean_df, str_df\n",
        "\n",
        "    def auto(self):\n",
        "        # 全联通网络\n",
        "        fcw = self.fully_connected_weight()\n",
        "\n",
        "        # fcw.to_excel(os.path.join(self.path, 'B-FCN_WEIGHT.xlsx'))\n",
        "        # fcw_length = self.length(self.df2net(fcw))\n",
        "        # fcw_length.to_excel(os.path.join(self.path, 'B-FCN_LENGTH.xlsx'))\n",
        "        # 最小生成树\n",
        "\n",
        "        mst = self.minimum_spanning_tree(self.df2net(fcw))\n",
        "        mst_df = self.net2df(mst)\n",
        "        mst_df.to_excel(os.path.join(self.path, 'B-MST_WEIGHT.xlsx'))\n",
        "        mst_length_df = self.length(mst)\n",
        "        print('mst length')\n",
        "        print(mst_length_df)\n",
        "\n",
        "        mst_length_df.to_excel(os.path.join(self.path, 'B-MST_LENGTH.xlsx'))\n",
        "\n",
        "        # fcn 1order 2order\n",
        "        # average length\n",
        "        # fcw_f1, fcw_f2 = self.get_feature(fcw_length)\n",
        "        # fcw_f1.to_excel(os.path.join(self.path, 'B-FCN_FEATURE_1.xlsx'))\n",
        "        # fcw_f2.to_excel(os.path.join(self.path, 'B-FCN_FEATURE_2.xlsx'))\n",
        "        # mean_df = np.mean()\n",
        "\n",
        "        # mst 1order 2order\n",
        "        mst_f1, mst_f2 = self.get_feature(mst_df)\n",
        "        mst_f1.to_excel(os.path.join(self.path, 'B-MST_FEATURE_1.xlsx'))\n",
        "        mst_f2.to_excel(os.path.join(self.path, 'B-MST_FEATURE_2.xlsx'))"
      ],
      "metadata": {
        "id": "jfVR34KMw70G"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 方式2：直接使用已经计算好的 corr 和 mv\n",
        "# 实例化 GetNetwork 类\n",
        "# Make sure in_dir is defined\n",
        "out_dir = in_dir # Or define a new output directory if needed\n",
        "get_network = GetNetwork(mv, corr)\n",
        "\n",
        "# Set the path attribute for saving files\n",
        "get_network.path = out_dir\n",
        "get_network.stk_list = corr.columns.tolist()\n",
        "\n",
        "\n",
        "# 调用 auto 方法生成网络输出\n",
        "get_network.auto()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B0iDVzKdmYy",
        "outputId": "ae1d86e2-89cb-4f60-f961-9de54947ac69"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "计算最小生成树……\n",
            "mst length\n",
            "               1         2         4         5         6         7         8  \\\n",
            "1       0.000000  1.563187  1.379960  1.003388  1.185569  2.104018  1.928958   \n",
            "2       1.563187  0.000000  1.553492  1.176920  0.926507  2.277550  2.102489   \n",
            "4       1.379960  1.553492  0.000000  0.840136  1.175875  1.783950  1.765706   \n",
            "5       1.003388  1.176920  0.840136  0.000000  0.799303  1.564194  1.389134   \n",
            "6       1.185569  0.926507  1.175875  0.799303  0.000000  1.899932  1.724872   \n",
            "...          ...       ...       ...       ...       ...       ...       ...   \n",
            "603993  1.767052  1.940584  1.603800  1.227228  1.562967  2.327858  1.832640   \n",
            "603996  1.557047  1.730579  1.236979  1.017223  1.352962  1.961037  1.942793   \n",
            "603997  1.600244  1.773775  1.280175  1.060420  1.396158  2.004233  1.985989   \n",
            "603998  1.257510  1.431042  0.937442  0.717686  1.053425  1.661500  1.643256   \n",
            "603999  1.189408  1.362940  0.869340  0.649584  0.985322  1.593397  1.575154   \n",
            "\n",
            "               9        10        11  ...    603987    603988    603989  \\\n",
            "1       0.886933  1.344101  1.167061  ...  1.123954  1.173591  1.225068   \n",
            "2       1.060465  1.517632  0.907999  ...  1.297486  1.347123  1.398600   \n",
            "4       0.723681  1.180849  1.157367  ...  0.803886  0.853523  1.061816   \n",
            "5       0.347109  0.804277  0.780794  ...  0.584130  0.633767  0.685244   \n",
            "6       0.682847  1.140015  0.293409  ...  0.919869  0.969505  1.020983   \n",
            "...          ...       ...       ...  ...       ...       ...       ...   \n",
            "603993  1.110773  1.567941  1.544458  ...  1.347794  1.397431  1.287249   \n",
            "603996  0.900768  1.357936  1.334454  ...  0.980973  1.030610  1.238903   \n",
            "603997  0.943965  1.401132  1.377650  ...  1.024169  1.073806  1.282100   \n",
            "603998  0.601231  1.058399  1.034917  ...  0.681436  0.562288  0.939367   \n",
            "603999  0.533129  0.990297  0.966814  ...  0.613333  0.662970  0.871264   \n",
            "\n",
            "          603990    603991    603993    603996    603997    603998    603999  \n",
            "1       1.230885  1.095472  1.767052  1.557047  1.600244  1.257510  1.189408  \n",
            "2       1.404417  1.269004  1.940584  1.730579  1.773775  1.431042  1.362940  \n",
            "4       0.910817  0.775404  1.603800  1.236979  1.280175  0.937442  0.869340  \n",
            "5       0.691061  0.555648  1.227228  1.017223  1.060420  0.717686  0.649584  \n",
            "6       1.026800  0.891387  1.562967  1.352962  1.396158  1.053425  0.985322  \n",
            "...          ...       ...       ...       ...       ...       ...       ...  \n",
            "603993  1.454725  1.319313  0.000000  1.780887  1.824084  1.481351  1.413248  \n",
            "603996  1.087904  0.952491  1.780887  0.000000  1.457262  1.114529  1.046427  \n",
            "603997  1.131100  0.995688  1.824084  1.457262  0.000000  1.157725  1.089623  \n",
            "603998  0.788367  0.652954  1.481351  1.114529  1.157725  0.000000  0.746890  \n",
            "603999  0.720265  0.584852  1.413248  1.046427  1.089623  0.746890  0.000000  \n",
            "\n",
            "[3570 rows x 3570 columns]\n",
            "get feature\n",
            "        Closeness   WDegree  E[return]\n",
            "stk                                   \n",
            "1        0.000095  2.694971        NaN\n",
            "2        0.000020  0.934010        NaN\n",
            "4        0.000084  0.770346        NaN\n",
            "5        0.000040  0.873680        NaN\n",
            "6        0.000195  2.438978        NaN\n",
            "...           ...       ...        ...\n",
            "603993   0.000097  2.689089        NaN\n",
            "603996   0.000129  1.625822        NaN\n",
            "603997   0.000074  0.790618        NaN\n",
            "603998   0.000055  0.835713        NaN\n",
            "603999   0.000040  0.873753        NaN\n",
            "\n",
            "[3570 rows x 3 columns]\n",
            "Index(['Closeness', 'WDegree', 'E[return]'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === 文件路径（按你的实际路径改） ===\n",
        "MST_PATH = os.path.join(str(years[0]), 'B-MST_FEATURE_1.xlsx')  # or '/content/drive/MyDrive/data/B-MST_FEATURE_1.xlsx'\n",
        "FIN_PATH = os.path.join('test1', 'yingli.xlsx')           # or '/content/drive/MyDrive/data/yingli.xlsx'\n",
        "\n",
        "print(MST_PATH, FIN_PATH)\n",
        "# 想要生成的年份（自行增删）\n",
        "\n",
        "# === 读取 MST 特征 ===\n",
        "# 已知工作表名：B-MST_FEATURE_1.xlsx 里是 'Sheet1'\n",
        "mst_raw = pd.read_excel(MST_PATH, sheet_name='Sheet1', header=0)\n",
        "\n",
        "# 统一列名：stk -> Stkcd；WDegree -> Deg；Closeness -> Clo\n",
        "mst = mst_raw.rename(columns={'stk':'Stkcd', 'WDegree':'Deg', 'Closeness':'Clo'})\n",
        "\n",
        "# 证券代码清洗（仅保留字母数字，转大写）\n",
        "mst['Stkcd'] = (mst['Stkcd'].astype(str)\n",
        "                .str.strip()\n",
        "                .str.replace(r'[^0-9A-Za-z]', '', regex=True)\n",
        "                .str.upper())\n",
        "\n",
        "# 数值列转型\n",
        "for c in ['Deg', 'Clo']:\n",
        "    if c in mst.columns:\n",
        "        mst[c] = pd.to_numeric(mst[c], errors='coerce')\n",
        "\n",
        "mst = mst.dropna(subset=['Stkcd']).drop_duplicates(subset=['Stkcd'])\n",
        "\n",
        "# === 读取财务（含 ROE 等）===\n",
        "# 已知工作表名：yingli.xlsx 里是 'sheet1'（注意小写）\n",
        "fin = pd.read_excel(FIN_PATH, sheet_name='sheet1', header=0)\n",
        "\n",
        "# 证券代码清洗\n",
        "fin['Stkcd'] = (fin['Stkcd'].astype(str)\n",
        "                .str.strip()\n",
        "                .str.replace(r'[^0-9A-Za-z]', '', regex=True)\n",
        "                .str.upper())\n",
        "\n",
        "# 提取年份（从 Accper 中抽取前4位数字）\n",
        "year_series = fin['Accper'].astype(str).str.extract(r'(\\d{4})', expand=False)\n",
        "fin['Year'] = pd.to_numeric(year_series, errors='coerce')\n",
        "\n",
        "# ROE 列（用户指定代码：F050503B）\n",
        "fin['ROE'] = pd.to_numeric(fin['F050503B'], errors='coerce')\n",
        "\n",
        "# 仅保留需要的列\n",
        "keep_cols = ['Stkcd', 'Year', 'ROE']\n",
        "if 'OperatingRevenue' in fin.columns:\n",
        "    keep_cols.append('OperatingRevenue')\n",
        "fin = fin[keep_cols]\n",
        "print(fin)\n",
        "# === 按年份合并并导出 ===\n",
        "outputs = []\n",
        "for y in years:\n",
        "    sub_fin = fin.loc[fin['Year'] == int(y)].copy()\n",
        "    print(sub_fin)\n",
        "    # 同一公司当年可能多条，取均值聚合\n",
        "    agg_cols = ['ROE'] + (['OperatingRevenue'] if 'OperatingRevenue' in sub_fin.columns else [])\n",
        "    sub_fin = sub_fin.groupby('Stkcd', as_index=False)[agg_cols].mean()\n",
        "\n",
        "    # 合并中心性 + 财务\n",
        "    merged = mst.merge(sub_fin, on='Stkcd', how='inner')\n",
        "\n",
        "    # 导出\n",
        "    out_path = f'merged_{y}.csv'\n",
        "    merged.to_csv(out_path, index=False)\n",
        "    outputs.append((y, out_path, merged.shape))\n",
        "\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ANBFRR-0ENa",
        "outputId": "e67eeb6a-43dc-4fcf-eefc-444c28352709"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2018/B-MST_FEATURE_1.xlsx test1/yingli.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Stkcd    Year       ROE\n",
            "0                  NaN       NaN\n",
            "1                  NaN       NaN\n",
            "2       000001  2001.0  0.096183\n",
            "3       000001  2002.0  0.049452\n",
            "4       000001  2002.0  0.083002\n",
            "...        ...     ...       ...\n",
            "529182  920819  2024.0  0.013173\n",
            "529183  920819  2024.0 -0.036395\n",
            "529184  920819  2024.0  0.003763\n",
            "529185  920819  2024.0 -0.110117\n",
            "529186  920819  2024.0 -0.002876\n",
            "\n",
            "[529187 rows x 3 columns]\n",
            "         Stkcd    Year       ROE\n",
            "73      000001  2018.0  0.029611\n",
            "74      000001  2018.0  0.059405\n",
            "75      000001  2018.0  0.089467\n",
            "76      000001  2018.0  0.107415\n",
            "242     000002  2018.0  0.009316\n",
            "...        ...     ...       ...\n",
            "529134  920819  2018.0  0.042508\n",
            "529135  920819  2018.0  0.089643\n",
            "529136  920819  2018.0  0.056182\n",
            "529137  920819  2018.0  0.109297\n",
            "529138  920819  2018.0  0.101713\n",
            "\n",
            "[32838 rows x 3 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('2018', 'merged_2018.csv', (2183, 5))]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.read_csv('merged_2018.csv')\n",
        "print(merged_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_jXtX543XrF",
        "outputId": "6d49c0a3-bba6-4779-f46e-69588076b3c6"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Stkcd       Clo       Deg  E[return]       ROE\n",
            "0     300001  0.000057  0.832074        NaN  0.026388\n",
            "1     300002  0.000038  0.881496        NaN -0.021804\n",
            "2     300003  0.000041  0.872053        NaN  0.101420\n",
            "3     300004  0.000059  0.826751        NaN -0.091088\n",
            "4     300005  0.000150  2.546240        NaN -0.005475\n",
            "...      ...       ...       ...        ...       ...\n",
            "2178  603993  0.000097  2.689089        NaN  0.057770\n",
            "2179  603996  0.000129  1.625822        NaN  0.018433\n",
            "2180  603997  0.000074  0.790618        NaN  0.109818\n",
            "2181  603998  0.000055  0.835713        NaN  0.050139\n",
            "2182  603999  0.000040  0.873753        NaN  0.015699\n",
            "\n",
            "[2183 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import spearmanr\n",
        "# ========== 读入数据 ==========\n",
        "\n",
        "df = pd.read_csv('merged_2018.csv')  # 若路径不同替换这里\n",
        "\n",
        "# 统一列名的大小写/别名（以防万一）\n",
        "rename_map = {}\n",
        "cols_lower = {c.lower(): c for c in df.columns}\n",
        "if 'clo' in cols_lower: rename_map[cols_lower['clo']] = 'Clo'\n",
        "if 'deg' in cols_lower: rename_map[cols_lower['deg']] = 'Deg'\n",
        "if 'roe' in cols_lower: rename_map[cols_lower['roe']] = 'ROE'\n",
        "df = df.rename(columns=rename_map)\n",
        "\n",
        "# 只保留需要的列并转浮点\n",
        "use = df[['Clo','Deg','ROE']].copy()\n",
        "for c in ['Clo','Deg','ROE']:\n",
        "    use[c] = pd.to_numeric(use[c], errors='coerce')\n",
        "\n",
        "# 去掉缺失\n",
        "use = use.dropna(subset=['Clo','Deg','ROE']).reset_index(drop=True)\n",
        "\n",
        "# ========== Spearman + 置换(QAP)检验 ==========\n",
        "# 置换检验：固定 X，随机置换 Y 的秩，计算两侧 p 值\n",
        "def permute_p_value(x, y, n_perm=10000, seed=2026):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    y = np.asarray(y, dtype=float)\n",
        "\n",
        "    # 有效样本掩码\n",
        "    mask = ~(np.isnan(x) | np.isnan(y))\n",
        "    x = x[mask]\n",
        "    y = y[mask]\n",
        "    n = len(x)\n",
        "    if n < 3:\n",
        "        return np.nan, np.nan, n\n",
        "\n",
        "    # 观测值\n",
        "    rho_obs, p_scipy = spearmanr(x, y, nan_policy='omit')\n",
        "\n",
        "    # 置换\n",
        "    cnt = 0\n",
        "    for _ in range(n_perm):\n",
        "        y_perm = rng.permutation(y)\n",
        "        rho_perm, _ = spearmanr(x, y_perm)\n",
        "        if abs(rho_perm) >= abs(rho_obs):\n",
        "            cnt += 1\n",
        "    p_perm = (cnt + 1) / (n_perm + 1)  # add-one 平滑\n",
        "\n",
        "    return rho_obs, p_scipy, p_perm, n\n",
        "\n",
        "pairs = [\n",
        "    ('Clo', 'ROE', 'Closeness', 'ROE'),\n",
        "    ('Deg', 'ROE', 'Degree',    'ROE'),\n",
        "]\n",
        "\n",
        "rows = []\n",
        "for xcol, ycol, xname, yname in pairs:\n",
        "    rho, p_scipy, p_perm, n = permute_p_value(use[xcol], use[ycol], n_perm=10000, seed=2025)\n",
        "    rows.append({\n",
        "        'X (MST Centrality)': xname,\n",
        "        'Y (Economic Measure)': yname,\n",
        "        'Spearman ρ': rho,\n",
        "        'Scipy p': p_scipy,\n",
        "        'Permutation p (QAP-style)': p_perm,\n",
        "        'N (firms)': n\n",
        "    })\n",
        "\n",
        "out = pd.DataFrame(rows)\n",
        "display(out.round(4))\n",
        "\n",
        "# （可选）保存到文件\n",
        "out.to_csv('spearman_qap_results_2018.csv', index=False)\n",
        "print('Saved -> spearman_qap_results_2018.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "wm55GKfq4LFD",
        "outputId": "365f746f-7a6d-4c35-9752-c34a760060dd"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  X (MST Centrality) Y (Economic Measure)  Spearman ρ  Scipy p  \\\n",
              "0          Closeness                  ROE     -0.0628   0.0034   \n",
              "1             Degree                  ROE     -0.0727   0.0007   \n",
              "\n",
              "   Permutation p (QAP-style)  N (firms)  \n",
              "0                     0.0032       2181  \n",
              "1                     0.0009       2181  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0260e0c3-7ab8-4fa1-9598-91c9af1f8601\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X (MST Centrality)</th>\n",
              "      <th>Y (Economic Measure)</th>\n",
              "      <th>Spearman ρ</th>\n",
              "      <th>Scipy p</th>\n",
              "      <th>Permutation p (QAP-style)</th>\n",
              "      <th>N (firms)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Closeness</td>\n",
              "      <td>ROE</td>\n",
              "      <td>-0.0628</td>\n",
              "      <td>0.0034</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>2181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Degree</td>\n",
              "      <td>ROE</td>\n",
              "      <td>-0.0727</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0009</td>\n",
              "      <td>2181</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0260e0c3-7ab8-4fa1-9598-91c9af1f8601')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0260e0c3-7ab8-4fa1-9598-91c9af1f8601 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0260e0c3-7ab8-4fa1-9598-91c9af1f8601');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-01b6e05c-5ca3-44c9-8a5e-ed3e1211231c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-01b6e05c-5ca3-44c9-8a5e-ed3e1211231c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-01b6e05c-5ca3-44c9-8a5e-ed3e1211231c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print('Saved -> spearman_qap_results_2018\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"X (MST Centrality)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Degree\",\n          \"Closeness\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y (Economic Measure)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ROE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spearman \\u03c1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007000357133746825,\n        \"min\": -0.0727,\n        \"max\": -0.0628,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          -0.0727\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Scipy p\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.001909188309203678,\n        \"min\": 0.0007,\n        \"max\": 0.0034,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0007\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Permutation p (QAP-style)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0016263455967290594,\n        \"min\": 0.0009,\n        \"max\": 0.0032,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0009\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N (firms)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2181,\n        \"max\": 2181,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2181\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved -> spearman_qap_results_2018.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 下面是实验2"
      ],
      "metadata": {
        "id": "Z9852rbvCESo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ===== 参数 =====\n",
        "YEAR = 2014\n",
        "PATH_MST_SPARSE = os.path.join(str(YEAR), 'B-MST_WEIGHT.xlsx')\n",
        "PATH_HLD_LIST = [\n",
        "    os.path.join('test2', 'HLD_Shareholders.xlsx') ,\n",
        "    os.path.join('test2', 'HLD_Shareholders1.xlsx') ,\n",
        "    os.path.join('test2', 'HLD_Shareholders2.xlsx') ,\n",
        "]\n",
        "OUT_PATH = f\"MST_pairs_holding_similarity_{YEAR}.xlsx\"\n",
        "\n",
        "# 仅使用“前十大股东”\n",
        "ONLY_TOP_N = 10  # None 则不限制\n",
        "\n",
        "# ======= 维度控制（强烈推荐打开其中至少一个） =======\n",
        "# 1) 只保留“稀疏 MST”里权重（或变换后值）最显著的少量边：\n",
        "KEEP_TOP_K_EDGES = 300_000        # 每年最多保留的边数；None 不限\n",
        "EDGE_WEIGHT_PERCENTILE = 0.85     # 或按分位数过滤（保留最靠前 15% 的边）；设 None 不用\n",
        "# 2) 每个股票只保留前 K 个“最大的股东权重”（而不是原表的前10名）：\n",
        "PER_STOCK_TOPK_SHAREHOLDERS = 10  # None 不限；会覆盖 ONLY_TOP_N 的效果\n",
        "\n",
        "# 列名候选\n",
        "STKCD_ALIASES   = [\"Stkcd\", \"stkcd\", \"code\", \"ticker\", \"证券代码\"]\n",
        "NAME_ALIASES    = [\"S0301a\", \"shareholder\", \"holder\", \"股东名称\", \"股东\"]\n",
        "RATIO_ALIASES   = [\"S0304a\", \"ratio\", \"percent\", \"percentage\", \"holding_pct\", \"持股比例\"]\n",
        "DATE_ALIASES    = [\"Reptdt\", \"reportdate\", \"stat_date\", \"enddate\", \"日期\", \"统计截止日期\"]\n",
        "RANK_ALIASES    = [\"S0306a\", \"rank\", \"holding_rank\", \"持股排名\"]\n",
        "\n",
        "EDGE_U_ALIASES  = [\"i\", \"src\", \"from\", \"stk_i\", \"code_i\", \"node_i\", \"u\"]\n",
        "EDGE_V_ALIASES  = [\"j\", \"dst\", \"to\", \"stk_j\", \"code_j\", \"node_j\", \"v\"]\n",
        "WEIGHT_ALIASES  = [\"w\", \"weight\", \"mst\", \"dist\", \"distance\", \"value\", \"val\"]\n",
        "\n",
        "# ===== 小工具 =====\n",
        "def _normalize_code(x):\n",
        "    if pd.isna(x): return np.nan\n",
        "    return str(x).strip()\n",
        "\n",
        "def _extract_year(x):\n",
        "    if pd.isna(x): return np.nan\n",
        "    y = pd.to_datetime(x, errors=\"coerce\")\n",
        "    if pd.notna(y): return y.year\n",
        "    s = str(x)\n",
        "    return int(s[:4]) if len(s) >= 4 and s[:4].isdigit() else np.nan\n",
        "\n",
        "def _pick_col(df, aliases):\n",
        "    lowmap = {c.lower(): c for c in df.columns}\n",
        "    for a in aliases:\n",
        "        if a.lower() in lowmap: return lowmap[a.lower()]\n",
        "    for c in df.columns:\n",
        "        if any(a.lower() in c.lower() for a in aliases): return c\n",
        "    return None\n",
        "\n",
        "def _cosine_fast(d_small, d_large, norm_small, norm_large):\n",
        "    \"\"\"\n",
        "    更快的余弦：只遍历较小的字典（OPTIMIZE）。\n",
        "    d_small/d_large: shareholder -> weight(float32)\n",
        "    norm_*: 预计算的 L2 范数（float32）\n",
        "    \"\"\"\n",
        "    if not d_small or not d_large or norm_small == 0 or norm_large == 0:\n",
        "        return np.nan\n",
        "    dot = 0.0\n",
        "    for k, w1 in d_small.items():\n",
        "        w2 = d_large.get(k)\n",
        "        if w2 is not None:\n",
        "            dot += float(w1) * float(w2)\n",
        "    return dot / (norm_small * norm_large) if dot > 0 else 0.0\n",
        "\n",
        "def _common_count(d1, d2):\n",
        "    if not d1 or not d2: return 0\n",
        "    # 交集大小（遍历较小集合）\n",
        "    if len(d1) <= len(d2):\n",
        "        return sum(1 for k in d1.keys() if k in d2)\n",
        "    else:\n",
        "        return sum(1 for k in d2.keys() if k in d1)\n",
        "\n",
        "# ===== 读取稀疏 MST =====\n",
        "mst_raw = pd.read_excel(PATH_MST_SPARSE, sheet_name=0, engine=\"openpyxl\")\n",
        "mst_raw.columns = [str(c).strip() for c in mst_raw.columns]\n",
        "\n",
        "def _try_edge_list(df):\n",
        "    u = _pick_col(df, EDGE_U_ALIASES + STKCD_ALIASES)\n",
        "    v = _pick_col(df, EDGE_V_ALIASES + STKCD_ALIASES)\n",
        "    w = _pick_col(df, WEIGHT_ALIASES)\n",
        "    if u is None or v is None or w is None:\n",
        "        return None\n",
        "    out = df[[u, v, w]].copy()\n",
        "    out.columns = [\"stk_i\", \"stk_j\", \"raw_weight\"]\n",
        "    return out\n",
        "\n",
        "pairs_df = _try_edge_list(mst_raw)\n",
        "\n",
        "if pairs_df is None:\n",
        "    first_col = mst_raw.columns[0]\n",
        "    colset = set(str(c).strip() for c in mst_raw.columns[1:])\n",
        "    rowlike = mst_raw[first_col].astype(str).str.strip()\n",
        "    if len(set(rowlike) & colset) >= max(3, int(0.6 * min(len(colset), len(rowlike)))):\n",
        "        mat = mst_raw.set_index(first_col)\n",
        "    else:\n",
        "        mat = mst_raw.copy()\n",
        "        if mat.shape[0] != mat.shape[1]:\n",
        "            raise RuntimeError(\"无法识别为边表，也不是方阵稀疏矩阵。\")\n",
        "        mat.index = mat.columns\n",
        "    mat.index = mat.index.map(_normalize_code)\n",
        "    mat.columns = [ _normalize_code(c) for c in mat.columns ]\n",
        "    codes = list(mat.columns)\n",
        "    rows = []\n",
        "    for i in range(len(codes)):\n",
        "        vals = mat.iloc[i, i+1:].astype('float64')\n",
        "        nonna = vals[vals.notna()]\n",
        "        for j_off, v in nonna.items():\n",
        "            rows.append((codes[i], j_off, float(v)))\n",
        "    pairs_df = pd.DataFrame(rows, columns=[\"stk_i\", \"stk_j\", \"raw_weight\"])\n",
        "\n",
        "# 清洗 + 无向去重\n",
        "pairs_df[\"stk_i\"] = pairs_df[\"stk_i\"].apply(_normalize_code)\n",
        "pairs_df[\"stk_j\"] = pairs_df[\"stk_j\"].apply(_normalize_code)\n",
        "pairs_df = pairs_df.dropna(subset=[\"stk_i\", \"stk_j\", \"raw_weight\"])\n",
        "pairs_df = pairs_df[pairs_df[\"stk_i\"] != pairs_df[\"stk_j\"]].copy()\n",
        "key = pairs_df.apply(lambda r: tuple(sorted([r[\"stk_i\"], r[\"stk_j\"]])), axis=1)\n",
        "pairs_df = pairs_df.loc[~key.duplicated()].copy()\n",
        "\n",
        "# 先用原权重做筛选，再变换（OPTIMIZE）\n",
        "if EDGE_WEIGHT_PERCENTILE is not None and 0 < EDGE_WEIGHT_PERCENTILE < 1:\n",
        "    thr = pairs_df[\"raw_weight\"].quantile(EDGE_WEIGHT_PERCENTILE)\n",
        "    pairs_df = pairs_df[pairs_df[\"raw_weight\"] >= thr].copy()\n",
        "\n",
        "if KEEP_TOP_K_EDGES is not None and len(pairs_df) > KEEP_TOP_K_EDGES:\n",
        "    pairs_df = pairs_df.nlargest(KEEP_TOP_K_EDGES, \"raw_weight\").copy()\n",
        "\n",
        "# 变换：mst_value = 1 - 原值（用 float32 降内存，OPTIMIZE）\n",
        "pairs_df[\"mst_value\"] = (1.0 - pd.to_numeric(pairs_df[\"raw_weight\"], errors=\"coerce\")).astype(\"float32\")\n",
        "pairs_df = pairs_df.drop(columns=[\"raw_weight\"]).reset_index(drop=True)\n",
        "\n",
        "# 只保留“出现过的股票”集合（OPTIMIZE）\n",
        "tickers = pd.unique(pairs_df[[\"stk_i\", \"stk_j\"]].values.ravel(\"K\"))\n",
        "tickers_set = set(tickers)\n",
        "\n",
        "# ===== 读取 HLD，仅保留涉及到的股票，且瘦身列（OPTIMIZE） =====\n",
        "hld_list = []\n",
        "use_cols_hint = set(STKCD_ALIASES + NAME_ALIASES + RATIO_ALIASES + DATE_ALIASES + RANK_ALIASES)\n",
        "for p in PATH_HLD_LIST:\n",
        "    if not os.path.exists(p):\n",
        "        continue\n",
        "    # 读进来后再列裁剪，避免 dtype 推断开销过大\n",
        "    df = pd.read_excel(p, sheet_name=0, engine=\"openpyxl\")\n",
        "    keep = [c for c in df.columns if any(h.lower() in c.lower() for h in use_cols_hint)]\n",
        "    df = df[keep].copy()\n",
        "    date_col = _pick_col(df, DATE_ALIASES)\n",
        "    if date_col is not None:\n",
        "        df[\"_Year\"] = df[date_col].apply(_extract_year)\n",
        "        df = df[df[\"_Year\"] == YEAR].copy()\n",
        "    else:\n",
        "        df[\"_Year\"] = YEAR\n",
        "    hld_list.append(df)\n",
        "\n",
        "holder_map = {}\n",
        "if hld_list:\n",
        "    d2 = pd.concat(hld_list, ignore_index=True)\n",
        "\n",
        "    col_stk   = _pick_col(d2, STKCD_ALIASES)\n",
        "    col_name  = _pick_col(d2, NAME_ALIASES)\n",
        "    col_ratio = _pick_col(d2, RATIO_ALIASES)\n",
        "    col_rank  = _pick_col(d2, RANK_ALIASES) if ONLY_TOP_N else None\n",
        "\n",
        "    # 关键：只保留出现在 pairs 的股票（OPTIMIZE）\n",
        "    d2[col_stk] = d2[col_stk].apply(_normalize_code)\n",
        "    d2 = d2[d2[col_stk].isin(tickers_set)].copy()\n",
        "\n",
        "    if col_name is not None:\n",
        "        d2[col_name] = d2[col_name].astype(str).str.strip()\n",
        "    else:\n",
        "        raise RuntimeError(\"缺少股东名称列，无法计算相似度。\")\n",
        "\n",
        "    # 若原数据无“排名”，也做“每股 topK 股东”（用权重排序，OPTIMIZE）\n",
        "    if col_ratio is not None:\n",
        "        r = pd.to_numeric(d2[col_ratio], errors=\"coerce\")\n",
        "        if pd.notna(r.max()) and r.max() > 1.5:\n",
        "            r = r / 100.0\n",
        "        d2[col_ratio] = r.astype(\"float32\")\n",
        "    else:\n",
        "        d2[col_ratio] = np.nan\n",
        "\n",
        "    if ONLY_TOP_N and col_rank is not None:\n",
        "        d2[col_rank] = pd.to_numeric(d2[col_rank], errors=\"coerce\")\n",
        "        d2 = d2[d2[col_rank] <= ONLY_TOP_N].copy()\n",
        "\n",
        "    # 覆盖式的“按权重取每股前K个股东”（比按排名更稳，OPTIMIZE）\n",
        "    if PER_STOCK_TOPK_SHAREHOLDERS is not None:\n",
        "        d2 = (d2\n",
        "              .sort_values([col_stk, col_ratio], ascending=[True, False])\n",
        "              .groupby(col_stk, as_index=False, group_keys=False)\n",
        "              .head(PER_STOCK_TOPK_SHAREHOLDERS))\n",
        "\n",
        "    # 聚合到“股票-股东唯一”，权重取最大\n",
        "    agg = d2.groupby([col_stk, col_name], dropna=True, as_index=False)[col_ratio].max()\n",
        "\n",
        "    # 预计算：每个股票的（股东→权重）字典 + L2 范数（float32，OPTIMIZE）\n",
        "    for stk, sub in agg.groupby(col_stk):\n",
        "        # 对缺失权重按 1 处理，且用 float32 缩内存\n",
        "        w = sub[col_ratio].fillna(1.0).astype(\"float32\").values\n",
        "        nms = sub[col_name].astype(str).values\n",
        "        d = {nms[i]: float(w[i]) for i in range(len(nms))}\n",
        "        norm = np.sqrt(np.dot(w, w)).astype(\"float32\")\n",
        "        holder_map[stk] = (d, float(norm))\n",
        "\n",
        "# ===== 仅计算出现在 pairs 的对子，且用更快的余弦（OPTIMIZE） =====\n",
        "cos_list, com_list = [], []\n",
        "get = holder_map.get\n",
        "for a, b, mv in pairs_df[[\"stk_i\", \"stk_j\", \"mst_value\"]].itertuples(index=False):\n",
        "    v1 = get(a); v2 = get(b)\n",
        "    if v1 is None or v2 is None:\n",
        "        cos_list.append(np.nan); com_list.append(0)\n",
        "        continue\n",
        "    d1, n1 = v1; d2, n2 = v2\n",
        "    # 遍历更小的 dict（加速）\n",
        "    if len(d1) <= len(d2):\n",
        "        cos = _cosine_fast(d1, d2, n1, n2)\n",
        "        com = _common_count(d1, d2)\n",
        "    else:\n",
        "        cos = _cosine_fast(d2, d1, n2, n1)\n",
        "        com = _common_count(d1, d2)\n",
        "    cos_list.append(cos); com_list.append(com)\n",
        "\n",
        "final = pairs_df[[\"stk_i\", \"stk_j\", \"mst_value\"]].copy()\n",
        "final[\"holding_cosine\"] = cos_list\n",
        "final[\"num_common_shareholders\"] = com_list\n",
        "\n",
        "# 大结果写盘（可开启分块写出，OPTIMIZE）\n",
        "final.to_excel(OUT_PATH, index=False)\n",
        "print(f\"完成：{OUT_PATH} | 边数：{len(final):,} | 覆盖股票数：{len(tickers_set):,}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diV7RFJTCE-q",
        "outputId": "6e1732ae-9f8c-480d-8760-22960bc3caba"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
            "/usr/local/lib/python3.12/dist-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
            "/usr/local/lib/python3.12/dist-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "完成：MST_pairs_holding_similarity_2014.xlsx | 边数：300,000 | 覆盖股票数：2,592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final.columns)\n",
        "print(len(final))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzEidv6DO3vM",
        "outputId": "dc93f079-30f5-4cb7-8b9e-a9aa7d4eb31f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['stk_i', 'stk_j', 'mst_value', 'holding_cosine',\n",
            "       'num_common_shareholders'],\n",
            "      dtype='object')\n",
            "300000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "# ========= I/O =========\n",
        "\n",
        "OUT_PATH = 'spearman_qap_results_mst_cos_2014.csv'\n",
        "\n",
        "# ========= 读入 & 清洗 =========\n",
        "df = final\n",
        "\n",
        "# 统一大小写/别名（以防有变）\n",
        "cols_lower = {c.lower(): c for c in df.columns}\n",
        "def col(name):\n",
        "    # 允许大小写/下划线差异\n",
        "    key = name.lower()\n",
        "    return cols_lower.get(key, name)\n",
        "\n",
        "xcol = col('mst_value')\n",
        "ycol = col('holding_cosine')\n",
        "\n",
        "use = df[[xcol, ycol]].copy()\n",
        "use[xcol] = pd.to_numeric(use[xcol], errors='coerce')\n",
        "use[ycol] = pd.to_numeric(use[ycol], errors='coerce')\n",
        "use = use.dropna().reset_index(drop=True)\n",
        "\n",
        "# ========= Spearman + 置换(QAP-style) =========\n",
        "def permute_p_value(x, y, n_perm=10000, seed=2026):\n",
        "    \"\"\"\n",
        "    固定 X，随机置换 Y 的秩（近似 QAP 的单调检验，适合稀疏对子列表）。\n",
        "    返回：rho_obs, p_scipy(two-sided), p_perm(two-sided), n\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    y = np.asarray(y, dtype=float)\n",
        "\n",
        "    mask = ~(np.isnan(x) | np.isnan(y))\n",
        "    x = x[mask]\n",
        "    y = y[mask]\n",
        "    n = len(x)\n",
        "    if n < 3:\n",
        "        return np.nan, np.nan, np.nan, n\n",
        "\n",
        "    rho_obs, p_scipy = spearmanr(x, y, nan_policy='omit')\n",
        "\n",
        "    cnt = 0\n",
        "    for _ in range(n_perm):\n",
        "        y_perm = rng.permutation(y)\n",
        "        rho_perm, _ = spearmanr(x, y_perm)\n",
        "        if abs(rho_perm) >= abs(rho_obs):\n",
        "            cnt += 1\n",
        "    p_perm = (cnt + 1) / (n_perm + 1)  # add-one 平滑\n",
        "\n",
        "    return rho_obs, p_scipy, p_perm, n\n",
        "\n",
        "rho, p_scipy, p_perm, n = permute_p_value(use[xcol], use[ycol], n_perm=10000, seed=2025)\n",
        "\n",
        "# 可选：单侧 p 值（如果你预期“距离越大，相似度越小”，即 rho < 0）\n",
        "p_perm_one_sided = p_perm / 2 if rho < 0 else 1 - (p_perm / 2)\n",
        "\n",
        "# ========= 输出表 =========\n",
        "out = pd.DataFrame([{\n",
        "    'X (MST value)': 'mst_value (1 - raw_weight)',\n",
        "    'Y (Cosine similarity)': 'holding_cosine',\n",
        "    'Spearman rho': rho,\n",
        "    'SciPy p (two-sided)': p_scipy,\n",
        "    'Permutation p (two-sided)': p_perm,\n",
        "    'Permutation p (one-sided, rho<0)': p_perm_one_sided,\n",
        "    'N (pairs)': n\n",
        "}])\n",
        "\n",
        "print(out.round(6))\n",
        "out.round(6).to_csv(OUT_PATH, index=False)\n",
        "print(f'Saved -> {OUT_PATH}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOnzCEUiuoGc",
        "outputId": "b57b2132-aa7b-4337-b9f7-ded4c9db0676"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                X (MST value) Y (Cosine similarity)  Spearman rho  \\\n",
            "0  mst_value (1 - raw_weight)        holding_cosine      0.205905   \n",
            "\n",
            "   SciPy p (two-sided)  Permutation p (two-sided)  \\\n",
            "0                  0.0                     0.0001   \n",
            "\n",
            "   Permutation p (one-sided, rho<0)  N (pairs)  \n",
            "0                           0.99995        868  \n",
            "Saved -> spearman_qap_results_mst_cos_2014.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Second, we examine whether firms with more common shareholders relationships are tend to be more similarity in our network. To utilize the same test frame, we convert edges to nodes via the line-graph transformation (Whitney, 1992), which represents each original edge as a node and connects two nodes if the corresponding edges share an endpoint."
      ],
      "metadata": {
        "id": "x2Xj0wQDmRbV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}